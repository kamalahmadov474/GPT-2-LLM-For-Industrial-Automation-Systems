{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamalahmadov474/GPT-2-LLM-For-Industrial-Automation-Systems/blob/main/LLM_Fine_Tuned_Chatbot(Filling_Tank).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97249e0b",
      "metadata": {
        "id": "97249e0b"
      },
      "source": [
        "Step 1: Install necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bba56772",
      "metadata": {
        "id": "bba56772",
        "outputId": "3e918154-fb41-439f-d5a4-75c6d4ff69ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\tuf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.51.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement datesets (from versions: none)\n",
            "ERROR: No matching distribution found for datesets\n",
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install transformers datesets accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ea75ce6",
      "metadata": {
        "id": "5ea75ce6"
      },
      "source": [
        "STEP 2: Prepare the dataset for Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b6d6b83",
      "metadata": {
        "id": "0b6d6b83",
        "outputId": "b14d62f2-e421-40c0-d801-abe918ceec9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\TUF\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "data = {\n",
        "    \"instruction\": [\n",
        "        \"Start filling the tank for 20 seconds\",\n",
        "        \"Discharge the tank for 15 seconds\",\n",
        "        \"Is the tank currently filling?\"\n",
        "    ],\n",
        "    \"output\": [\n",
        "        \"write_coil(0, True)\",                         # Fill\n",
        "        \"write_coil(1, True)\",                         # Discharge\n",
        "        \"read_discrete_input(1)\"                     # Filling (Input 1)\n",
        "    ]\n",
        "}\n",
        "dataset = Dataset.from_dict(data)\n",
        "# Normalize function\n",
        "def normalize(text):\n",
        "    return re.sub(r\"\\s+\", \"\", text.lower())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1357f9f",
      "metadata": {
        "id": "e1357f9f"
      },
      "source": [
        "STEP 3: LLM Fine-Tune the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "050a34ea",
      "metadata": {
        "id": "050a34ea",
        "outputId": "e48789b0-bfb4-417e-8ff0-c989c175aa43"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 71.80 examples/s]\n",
            "C:\\Users\\TUF\\AppData\\Local\\Temp\\ipykernel_20364\\1849354702.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "c:\\Users\\TUF\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:37, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.241000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=10, training_loss=2.2410154342651367, metrics={'train_runtime': 44.6814, 'train_samples_per_second': 0.336, 'train_steps_per_second': 0.224, 'total_flos': 3919380480000.0, 'train_loss': 2.2410154342651367, 'epoch': 5.0})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
        "\n",
        "model_name = \"gpt2\"  # Use a small model for quick testing\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Set pad_token to eos_token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def preprocess(example):\n",
        "    # Encode with padding and truncation\n",
        "    inputs = tokenizer(\n",
        "        f\"User: {example['instruction']}\\nBot: {example['output']}\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",  # Add padding\n",
        "        max_length=512  # Set a maximum length\n",
        "    )\n",
        "\n",
        "    inputs['labels'] = inputs['input_ids'].copy()\n",
        "    return inputs\n",
        "\n",
        "# Apply the preprocessing to the dataset\n",
        "tokenized_dataset = dataset.map(preprocess, remove_columns=dataset.column_names)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./modbus-llm\",\n",
        "    per_device_train_batch_size=2,\n",
        "    num_train_epochs=5,\n",
        "    logging_steps=10,\n",
        "    save_steps=100,\n",
        "    fp16=True,\n",
        "    overwrite_output_dir=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aba9223",
      "metadata": {
        "id": "7aba9223"
      },
      "source": [
        "STEP 4: Connect to CODESYS / Factory I/O via Modbus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab192e77",
      "metadata": {
        "id": "ab192e77"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from pymodbus.client import ModbusTcpClient\n",
        "\n",
        "# Attempt to connect to Modbus server\n",
        "client = ModbusTcpClient('127.0.0.1', port=502)\n",
        "if not client.connect():\n",
        "    raise ConnectionError(\"‚ùå Failed to connect to Modbus server at 127.0.0.1:502\")\n",
        "\n",
        "print(\"‚úÖ Modbus connection established.\")\n",
        "import re\n",
        "# Get user instruction\n",
        "# Get user input\n",
        "instruction = input(\"üß† Enter your instruction: \").strip()\n",
        "normalized_instruction = normalize(instruction)\n",
        "\n",
        "# Find matching instruction\n",
        "matched_idx = None\n",
        "for idx, inst in enumerate(dataset[\"instruction\"]):\n",
        "    if normalize(inst) == normalized_instruction:\n",
        "        matched_idx = idx\n",
        "        break\n",
        "\n",
        "if matched_idx is not None:\n",
        "    command_str = dataset[\"output\"][matched_idx]\n",
        "    print(f\"ü§ñ Matched instruction: {dataset['instruction'][matched_idx]}\")\n",
        "    print(f\"‚öôÔ∏è Executing command(s): {command_str}\")\n",
        "\n",
        "    commands = [cmd.strip() for cmd in command_str.split(\";\")]\n",
        "    for cmd in commands:\n",
        "        match = re.match(r\"write_coil\\((\\d+),\\s*(True|False)\\)\", cmd, re.IGNORECASE)\n",
        "        if match:\n",
        "            address = int(match.group(1))\n",
        "            value = match.group(2).lower() == \"true\"\n",
        "            result = client.write_coil(address, value)\n",
        "            print(f\"‚úÖ Coil {address} written to {value}: {result}\")\n",
        "        else:\n",
        "            print(f\"‚ÑπÔ∏è Skipped: '{cmd}' is not a write command\")\n",
        "else:\n",
        "    print(\"‚ùå Instruction not recognized.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}